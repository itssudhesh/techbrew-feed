<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
<channel>
<title>Tech Brew</title>
<link>https://www.techbrew.com</link>
<description>Tech Brew scraped feed</description>
<item>
  <title>Google’s Gemini for navigation is full of trivia, but can struggle with directions</title>
  <link>https://www.techbrew.com/stories/2026/02/17/google-gemini-navigation-test</link>
  <pubDate>2026-02-17</pubDate>
  <dc:creator>Patrick Kulp</dc:creator>
  <category>Emerging Tech</category>
  <description>Morning Brew took a few walking and biking trips with Google’s new AI assistant.</description>
  <content:encoded><![CDATA[<div class="style__ArticleBodyWrapper-sc-9b30af34-3 iUHyfu article-body-content" id="article-body-content"><p class="dist__StyledText-sc-5791265-8 bdIWsa">Google’s Gemini navigation assistant promises “a knowledgeable friend in the passenger seat.” More recently, that “friend” can now bike or walk along with you, too.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">I set out as both a pedestrian and a cyclist on both coasts to test Gemini’s value, and found it to be a chatty companion that was perhaps better at dispensing trivia than holding a map right side up.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Google first brought Gemini to driving directions in November, then expanded it to walking and cycling directions in recent weeks. The idea is to give travelers a hands-free, conversational way to gauge ETAs, ask about things like attractions or restaurants along a route, or just wonder aloud where exactly they are.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">If you’ve given Google more digital permissions than I have, you can also have Gemini text a friend that you’re running late or check your calendar for upcoming events.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">The rollout comes as automakers are <a href="https://www.techbrew.com/stories/2025/11/10/ai-vehicles-gm-rivian" target="_blank">increasingly looking for ways</a> to integrate generative AI into in-car experiences—in some cases, <a href="https://www.techbrew.com/stories/2025/09/04/google-cloud-ai-automakers" target="_blank">with Google’s help</a>. GenAI could provide a hands-free way to interface with directions <a href="https://www.techbrew.com/stories/2024/01/17/ai-chatgpt-in-cars-ces" target="_blank">as well as navigate</a> all of the digital amenities that modern vehicles now offer. Why not offer the same functionality to walkers and cyclists?</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">For one, I felt a little foolish talking aloud to an AI while walking down a crowded city street. Maybe it’s just me, but I found the experience of asking my phone, “What neighborhood am I in?”—a query suggested by Google—to be a bit embarrassing when passersby were in earshot.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">It certainly did know which neighborhoods I was in, however, whether it was San Francisco’s Mission District or the border of the Lower East Side and the East Village in Manhattan. Or even a much smaller neighborhood in a suburban Bay Area city. And its grasp of place-based trivia is extensive.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Walking down Delancey Street in Manhattan, I asked it, intentionally vaguely, about a nearby diner featured in a documentary. It identified the modern iteration of Shopsin’s General Store in Essex Market as the subject of a 2004 film, <em>I Like Killing Flies</em>. It could identify and tell me the history of various theaters in the Mission District. It successfully suggested local stores where I could buy a Valentine’s Day present, and identified convenience stores to buy particular items.</p><h3 class="dist__StyledText-sc-5791265-8 fPysEE"><strong>Map troubles</strong></h3><p class="dist__StyledText-sc-5791265-8 bdIWsa">I’ve tried to use AI for biking navigation before, and my very cursory foray was fraught. Last summer, I tested ChatGPT’s ability to give me info on a route along the Empire State Trail through a remote part of the Adirondack Mountains. <em>(Editor’s note: Patrick is extremely qualified to conduct these tests. He’s an avid runner and cyclist, routinely taking a spot on the podium for Morning Brew’s Strava Activity Challenges.)</em></p><p class="dist__StyledText-sc-5791265-8 bdIWsa">The guidance it gave me at the time sounded well and good at first, until I realized much of it was unmoored from any geographic reality. It told me a stretch of trail was 25 miles in one response, then 15 miles in the next. (It was actually 41 miles.) ChatGPT imagined roads with spacious shoulders and rolling terrain instead of much more real steep, narrow hills. This seemed to be one use of AI that was more prone to hallucinations (this was a whole generation of GPT ago, though, to be fair).</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">One would assume Gemini to be more tethered to Google Maps. I didn’t get it on any remote mountain trails, thanks to snow and frigid temperatures, but Gemini struggled to turn conversations into routes in Livermore, California, and in Manhattan.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">In one case, I asked Gemini to tweak its directions to incorporate a nearby trail instead of street sidewalks. Gemini described the route I wanted to a T. But when Maps tried to alter the directions accordingly, it inexplicably added in 13 miles and a tour of the neighboring city of Pleasanton. It seemed that despite the trail stretching between the two cities, there was only one trailhead labeled as such on the map. Trying to get it to route along the correct trail by voice ended up being more trouble than it was worth.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">At another point, Gemini and I talked through a plan for Valentine’s Day shopping. It dutifully identified nearby florists, but this was on February 8—too far from the actual holiday. It then crafted a route that would hit a jewelry shop and a chocolate store; however, I told it I didn’t want to go to that particular jewelry store, and it seemed to understand. We discussed a new route that would encompass a gift shop and a chocolate store. But when I set off, having been assured of updated directions, I found it was incorrectly routing me once more to the jewelry store I’d rejected. OK, I can take the hint.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">These types of negotiations sometimes resulted in a desired route, but I ultimately found it easier to just pull over my bike or stop walking and type things in by hand. Maybe if you’re behind the wheel on the road, it makes sense. And if you don’t mind awkwardly conversing with your phone on the street, it can definitely offer you some fun facts on your immediate surroundings. But for now, I’ll be sticking to the classic Google Maps when I simply need to get from Point A to Point B.</p></div>]]></content:encoded>
  <media:content url="https://cdn.sanity.io/images/bl383u0v/production/5531584c79357f3739a59ca63eec7dd5a1d9b707-3000x2000.jpg?rect=0,212,3000,1575&amp;w=1200&amp;h=630&amp;q=70&amp;fit=crop&amp;auto=format" medium="image"/>
</item>
<item>
  <title>A red line deadline for Anthropic</title>
  <link>https://www.techbrew.com/stories/2026/02/25/pentagon-deadline-anthropic</link>
  <pubDate>2026-02-25</pubDate>
  <dc:creator>Patrick Kulp</dc:creator>
  <category>Emerging Tech</category>
  <description>Tech Brew keeps business leaders up-to-date on the latest innovations, automation advances, policy shifts, and more, so they can make informed decisions about tech.</description>
  <content:encoded><![CDATA[<div class="style__ArticleBodyWrapper-sc-9b30af34-3 iUHyfu article-body-content" id="article-body-content"><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>TL;DR: </strong>The clock is now ticking on <a href="https://www.techbrew.com/stories/anthropic-pentagon-ai-military-use" target="_blank">the dustup between Anthropic and the Pentagon</a>. Defense Secretary Pete Hegseth gave the company until Friday at 5:01pm to meet its demands during a reportedly <a href="https://www.axios.com/2026/02/24/anthropic-pentagon-claude-hegseth-dario" target="_blank">“tense” face-to-face</a> yesterday, a senior defense official confirmed to Tech Brew. The government is floating drastic legal measures to force Anthropic to roll back certain AI guardrails, but the company is said to be digging in its heels—despite rolling back some of its protections separately, <a href="https://time.com/7380854/exclusive-anthropic-drops-flagship-safety-pledge/" target="_blank">if they affect its competitiveness</a>. The next couple days might show just how resilient AI ethics pledges are in the face of potential business losses and <a href="https://www.cnn.com/2026/02/24/tech/hegseth-anthropic-ai-military-amodei" target="_blank">DC pariah status</a>. It’s also a test of just how irreplaceable Anthropic’s AI is.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>What happened: </strong>An Anthropic spokesperson said that yesterday’s Pentagon meeting was a “good-faith conversation,” but a defense official’s description to Axios—“<a href="https://www.axios.com/2026/02/24/anthropic-pentagon-claude-hegseth-dario" target="_blank">not warm and fuzzy at all</a>”—sounds a bit more on point.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Hegseth reiterated to Anthropic CEO Dario Amodei that the department will declare Anthropic a “supply chain risk” and <em>also</em> invoke the Defense Production Act to force the company to allow use on the Pentagon’s terms—two different steps that would seem to contradict one another (OpenAI, Google, and xAI have all accepted the terms). Anthropic’s Claude was the only AI model approved for use in classified systems. As of Monday, the government has granted Elon Musk’s xAI (and its <a href="https://www.techbrew.com/stories/2026/01/09/grok-paywall-deepfake-problem" target="_blank">controversial Grok model</a>) that status and is close to doing so with other AI companies it’s in talks with, the senior defense official told us (OpenAI has already been <a href="https://www.semafor.com/article/02/11/2026/how-openai-got-comfortable-with-the-pentagon-using-chatgpt-for-war" target="_blank">ramping up work with the military</a>).</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Anthropic’s leverage:</strong> Claude holds some cards that Grok doesn’t have, though: It’s generally considered to be better. And a senior administration official told Axios that other models “are just behind” when it comes to specialized government use cases.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Anthropic has positioned itself well for national security, and its models perform well on the use cases the Pentagon needs, according to Owen Daniels, associate director of analysis at Georgetown’s Center for Security and Emerging Technology.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">And it may be hard to remove Claude depending on how deeply it’s already embedded, Chirag Mehta, vice president and principal analyst at Constellation Research told us. Anthropic’s relationship with Palantir also <a href="https://www.semafor.com/article/02/17/2026/palantir-partnership-is-at-heart-of-anthropic-pentagon-rift" target="_blank">makes Claude tricky to disentangle</a>.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“Swapping models is easy on paper but hard in production,” Mehta said. “The real work sits in the integration, the evaluations, and the accreditation trail.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Why it matters: </strong>“Using the DPA to try to strongarm a private company to do what they want just strikes me as unprecedented and uncalled for,” Kristian Stout, director of innovation policy at the International Center for Law and Economics, told us. “We're not at war, we're not at threat of war. There's no asteroid landing that we need sudden emergency help with.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">The government also doesn’t usually label companies as “supply chain risks” unless they’re doing something like working with a foreign adversary. But Daniels said it is also “very uncommon” for a government contractor to draw boundaries the way Anthropic is.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“Part of the challenge here stems from the clash of cultures of these two organizations,” Daniels said. “From the Pentagon's perspective, there's […] the precedent that this could set in terms of companies trying to dictate terms to DoD.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>What comes next: </strong>Anthropic has until 5:01pm on Friday to comply with the Pentagon’s demands. But there’s always a chance the deadline could be kicked down the road. And Anthropic does hold some leverage here—the Pentagon clearly wants to keep using its models. But it’s also out on a limb without its industry peers backing up its stance. “They're really stepping out on their own in this regard,” Daniels said. <em>—PK</em></p></div>]]></content:encoded>
  <media:content url="https://morningbrew.com/cdn-cgi/image/width=1200,height=630,quality=70,format=auto/https://storage.morningbrew.com/image/2026-02-25/image-7149c152684863af164cf481df0b239ab9acd17a-1500x1000-jpg/TB_PentagonAnthropic_SM_022526.jpg" medium="image"/>
</item>
<item>
  <title>Enterprise on edge</title>
  <link>https://www.techbrew.com/stories/openai-anthropic-enterprise-panic</link>
  <pubDate>2026-02-24</pubDate>
  <dc:creator>Whizy Kim</dc:creator>
  <category>Emerging Tech</category>
  <description>Tech Brew keeps business leaders up-to-date on the latest innovations, automation advances, policy shifts, and more, so they can make informed decisions about tech.</description>
  <content:encoded><![CDATA[<div class="style__ArticleBodyWrapper-sc-9b30af34-3 iUHyfu article-body-content" id="article-body-content"><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>TL;DR:</strong> Within 36 hours of one another, Anthropic and OpenAI both made major enterprise pushes. Just days before that, a <a href="https://www.citriniresearch.com/p/2028gic" target="_blank">viral memo</a> imagined how those kinds of moves would hollow out white-collar work (and even be the end of enterprise). Now, investors and executives are caught between embracing AI and wondering if they're accelerating their own obsolescence.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>What happened:</strong> Yesterday, OpenAI unveiled partnerships with four major consulting firms, including McKinsey and Accenture, to roll out its nascent Frontier enterprise system. The goal: help large organizations deploy AI agents inside existing operations. Anthropic made a parallel move. The company announced it’s expanding plugins for Claude Cowork, adding custom skills—for everything from financial analysis to HR onboarding—to tools their employees already use. But perhaps the most telling detail: It revealed that <a href="https://claude.com/blog/how-ai-helps-break-cost-barrier-cobol-modernization" target="_blank">Claude can now modernize COBOL</a>, the decades-old programming language that still handles 95% of US ATM transactions and underpins IBM's consulting empire.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>The enterprise race heats up: </strong>Companies spent about <a href="https://menlovc.com/perspective/2025-the-state-of-generative-ai-in-the-enterprise/" target="_blank">$37 billion on generative AI</a> last year, which is <a href="https://menlovc.com/perspective/2025-the-state-of-consumer-ai/" target="_blank">roughly triple consumer spending</a>, and that gap is widening. OpenAI is trying to claw back its enterprise revenue share, which has dropped since 2023. Meanwhile, Anthropic already generates most of its revenue from corporate customers and can’t afford to cede that advantage. Google is gaining fast too, selling <a href="https://blog.google/company-news/inside-google/message-ceo/alphabet-earnings-q4-2025/" target="_blank">8 million paid Gemini Enterprise seats</a> in about four months.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>The frenemies’ dilemma: </strong>According to The Information, OpenAI leaders told investors last week that they expect <a href="https://www.theinformation.com/newsletters/the-briefing/software-quandary-openai-anthropic-frenemies-foes" target="_blank">future products to replace software</a> from SaaS juggernauts like Salesforce, Workday, Adobe, Slack, and Atlassian—the exact tools Frontier is designed to integrate with. Anthropic hasn’t been as blunt, but its launches have contributed to <a href="https://www.businessinsider.com/claude-ai-tools-tech-selloff-software-apocalypse-cybersecurity-anthropic-ibm-2026-2" target="_blank">the hit on software stocks</a>.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">So why do these companies keep inking what seems to be their own demise? Because the alternative—watching a competitor integrate AI first—might be scarier than partnering with the company building their replacement. For now.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Gasoline, meet fire: </strong>Over the weekend, financial research firm Citrini Research published a speculative scenario titled "<a href="https://www.citriniresearch.com/p/2028gic" target="_blank">The 2028 Global Intelligence Crisis</a>," imagining widespread white-collar displacement and AI agents bypassing platforms altogether. The report took aim at Uber, DoorDash (whose <a href="https://x.com/andyfang/status/2025821445016973722" target="_blank">co-founder responded on X</a>), credit card companies like Amex and Visa, and SaaS platforms like ServiceNow. Their stocks all took a hit.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">The Citrini memo went viral not because it was rigorous—it was a fictional thought experiment, not a forecast—but because it made legible a fear that this week’s enterprise announcements sharpened: that the AI being sold to businesses will also replace the businesses themselves.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Bottom line: </strong>The enterprise push will continue. The jumpiness probably will too. But, as Derek Thompson observed, not even the executives building these tools <a href="https://x.com/DKThomp/status/2026289817735098688" target="_blank">know how this plays out</a>. —<em>WK</em></p></div>]]></content:encoded>
  <media:content url="https://morningbrew.com/cdn-cgi/image/width=1200,height=630,quality=70,format=auto/https://storage.morningbrew.com/image/2026-02-24/image-ff494c0ef63782b0c6f7666c4539be996308292e-2000x1334-jpg/TB-Download-AIBurnout-0226.jpg" medium="image"/>
</item>
<item>
  <title>A Tale of Two Claudes</title>
  <link>https://www.techbrew.com/stories/2026/02/23/a-tale-of-two-claudes</link>
  <pubDate>2026-02-23</pubDate>
  <dc:creator>Whizy Kim</dc:creator>
  <category>Emerging Tech</category>
  <description>Tech Brew keeps business leaders up-to-date on the latest innovations, automation advances, policy shifts, and more, so they can make informed decisions about tech.</description>
  <content:encoded><![CDATA[<div class="style__ArticleBodyWrapper-sc-9b30af34-3 iUHyfu article-body-content" id="article-body-content"><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>TL;DR:</strong> We pitted Anthropic's two flagship models against each other on a sliding scale of normie tasks—forms, spreadsheets, trip planning, research. <a href="https://www.anthropic.com/news/claude-sonnet-4-6" target="_blank">Claude Sonnet 4.6</a> isn’t better than the premium Opus 4.6 model—but it is cheaper and more than good enough for most. Opus still wins when precision, judgment, or careful planning matters.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Some background: </strong>AI model updates aren't just about raw capabilities anymore—they’re about value for money. Case in point: Anthropic's Sonnet 4.6, released last Tuesday, claims to deliver <a href="https://www.axios.com/2026/02/17/anthropic-new-claude-sonnet-faster-cheaper" target="_blank">near-Opus performance</a> at a fraction of the cost. That matters, because the latest Opus costs more per token—the unit AI models use to measure and process text—so even users on Anthropic's Max plan <a href="https://github.com/anthropics/claude-code/issues/23706" target="_blank">burn through their limits</a> quickly. (For every three Opus queries, you can do about five with Sonnet for the same price.) Here’s how they stacked up in our testing:</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Clear Sonnet wins:</strong></p><ul><li><strong>Filling out a multipage auto insurance quote form. </strong>I<strong> </strong>told it to make up placeholder info to get an online quote from Progressive. Sonnet was a few minutes faster; Opus seemed to get tripped up by the birth date field.</li><li><strong>Finding current news on X. </strong>Both finished in roughly the same amount of time, but Sonnet surfaced actually recent news, while Opus brought up topics from as far back as January 2025.</li></ul><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Clear Opus wins:</strong></p><ul><li><strong>Vibe coding apps. </strong>I wanted to make a tool that autorenames my screenshots based on what’s in the image. Sonnet asked questions, but delivered an app that didn’t work. Opus caught bugs and gave me a working tool on the first try.</li><li><strong>Processing massive docs.</strong> Sonnet handled a single PDF without issue, but froze when asked to download all of the Mag 7's annual reports at once. Opus did it in about five minutes—and it actually grabbed PDFs; Sonnet got HTM files. (Once the files were in hand, both did a comparable job on the analysis itself.)</li><li><strong>Philosophy, ethics, and history questions. </strong>Opus took clearer positions and followed instructions more precisely. When asked what the first printed book was, Opus said the Diamond Sutra. Sonnet led with the Gutenberg Bible, then added caveats on “movable type” before landing on the correct answer.</li></ul><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Toss-ups</strong> <strong>(where you’re probably fine to use Sonnet):</strong></p><ul><li><strong>Spreadsheet analysis. </strong>Opus was faster because it clarified how much detail I wanted first; Sonnet asked no questions, but because it pulled a broader data set, analysis ended up being more detailed and interesting.</li><li><strong>Creating custom Skills. </strong>I asked them to make a Cowork Skill to log how long each prompt and response took within a task. Both got the job done; Opus's formatting was slightly neater.</li><li><strong>Group trip itinerary. </strong>Sonnet’s output involved more color and a peppering of cringe emojis. Opus avoided an incorrect assumption from a screenshot I provided. Both included roughly the same info and activity recs.</li></ul><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>The verdict:</strong> Think of Sonnet as the Goldilocks option of the Claude family, sitting between Haiku—the cheapest model—and Opus. Opus is more meticulous, self-aware, and reliable, but that level of precision is expensive and, for most tasks, unnecessary. Only upgrade when: You can’t afford silent errors, you’re handling complex code or multidocument reasoning, or you want the model to challenge your assumptions.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>What’s next: </strong>Frontier labs used to compete on pure intelligence. Now they’re competing on value per token. Sonnet doesn’t dethrone Opus—but it doesn’t need to. It’s “good enough” at a price that makes it the practical default. In that sense, the future of AI may not belong to the smartest model. It may belong to the one that delivers 90% of the performance at 60% of the cost. <em>—WK</em></p></div>]]></content:encoded>
  <media:content url="https://morningbrew.com/cdn-cgi/image/width=1200,height=630,quality=70,format=auto/https://storage.morningbrew.com/image/2026-02-23/image-e9f786aa7083a72078d0aee5c5444fe8da31d407-1500x1000-jpg/TB-Download-SonnetOpus-0226.jpg" medium="image"/>
</item>
<item>
  <title>The great RAM grab has begun</title>
  <link>https://www.techbrew.com/stories/2026/02/20/the-great-ram-grab-has-begun</link>
  <pubDate>2026-02-20</pubDate>
  <dc:creator>Alex Carr</dc:creator>
  <category>Emerging Tech</category>
  <description>Tech Brew keeps business leaders up-to-date on the latest innovations, automation advances, policy shifts, and more, so they can make informed decisions about tech.</description>
  <content:encoded><![CDATA[<div class="style__ArticleBodyWrapper-sc-9b30af34-3 iUHyfu article-body-content" id="article-body-content"><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>TL;DR:</strong> AI giants can afford all the memory they need. Everyone else will pay the price. Companies like Alphabet, Microsoft, and OpenAI are buying up massive amounts of memory to power their AI ambitions, taking up supply that would normally go to consumer tech. The result: higher prices, delayed products, and fewer upgrades for phones, laptops, and TVs. Enter: the “<a href="https://www.theverge.com/tech/880812/ramageddon-ram-shortage-memory-crisis-price-2026-phones-laptops" target="_blank">RAMageddon</a>.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>What happened: </strong>Building out AI infrastructure is a memory-intensive business. The servers powering chatbots, copilots, and AI tools run on specialized chips that consume vastly more RAM (aka the workhorse of virtually all tech) with each new generation. As tech giants use their deep pockets to snap up millions of these chips to build out data centers, they're consuming a disproportionate share of global memory production.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">As of 2021, <a href="https://electronics360.globalspec.com/article/18157/94-of-dram-market-controlled-by-three-companies" target="_blank">just three companies</a>—Samsung, SK Hynix, and Micron—control over 90% of the world’s DRAM (dynamic random access memory), and right now, they’re allocating more supply to AI infrastructure than personal devices. While suppliers <em>are</em> planning to build new memory fabrication plants, increases in supply likely won’t arrive for years. For now, the pressure is already showing up in prices: The cost of one major kind of DRAM jumped 75% in just a month, from December 2025 to January 2026.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Why it matters: </strong>RAM allows your phone to juggle apps, your laptop to run software, and your TV to stream Netflix without freezing. The problem is who's buying it. Tech giants can secure RAM at almost any price, leaving consumer tech companies and their customers competing for what’s left.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>What’s affected: </strong>Chipmakers like <a href="https://www.cnbc.com/2026/02/05/qualcomm-stock-memory-shortage-warning.html" target="_blank">Qualcomm have warned</a> that smartphone manufacturers will face tighter memory supplies and higher costs. (<a href="https://www.wsj.com/tech/the-ai-boom-is-coming-for-apples-profit-margins-4774013d" target="_blank">Apple’s feeling the squeeze</a>.) According to The Verge, laptop makers including Lenovo, Dell, and HP are reportedly planning <a href="https://www.theverge.com/tech/880812/ramageddon-ram-shortage-memory-crisis-price-2026-phones-laptops" target="_blank">price increases</a> of 10% to 30% to offset rising expenses. <a href="https://www.bloomberg.com/news/articles/2026-02-15/rampant-ai-demand-for-memory-is-fueling-a-growing-chip-crisis" target="_blank">Gaming hardware</a> has also taken a hit: Sony’s next PlayStation could get delayed until 2029, and the Nintendo Switch 2 may be more expensive. Even <a href="https://www.axios.com/2026/02/19/ai-tv-prices-ram-memory-chips" target="_blank">TVs are likely to become pricier</a>, with research firm TrendForce calling increases "unavoidable” and predicting global supply down almost 1%. The squeeze is especially hard on smaller companies, and in some cases, that could mean canceled products. Or companies exiting markets entirely.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>What’s next: </strong>Industry leaders expect tight supply and elevated prices could continue for years—right now, 2028 looks like the base case for things to go back to normal. It’s not quite<em> </em>like the great Toilet Paper Panic of 2020, so shelves aren’t likely to go empty overnight, but analysts warn consumers will increasingly see higher prices, delayed launches, or devices that deliver less for the same cost. <a href="https://www.fastcompany.com/91495430/heres-every-cool-tech-thing-the-ai-ram-crunch-is-ruining" target="_blank">For a list of products affected by the RAM shortage, click here. </a><em>—AC</em></p></div>]]></content:encoded>
  <media:content url="https://morningbrew.com/cdn-cgi/image/width=1200,height=630,quality=70,format=auto/https://storage.morningbrew.com/image/2026-02-20/image-6c939158c4d9213b4e42d6bce76d315986cd8c99-3000x2000-png/TB_Download_SM_02202026.png" medium="image"/>
</item>
<item>
  <title>Meta does an about-face</title>
  <link>https://www.techbrew.com/stories/2026/02/19/meta-does-an-about-face</link>
  <pubDate>2026-02-19</pubDate>
  <dc:creator>Alex Carr</dc:creator>
  <category>Emerging Tech</category>
  <description>Tech Brew keeps business leaders up-to-date on the latest innovations, automation advances, policy shifts, and more, so they can make informed decisions about tech.</description>
  <content:encoded><![CDATA[<div class="style__ArticleBodyWrapper-sc-9b30af34-3 iUHyfu article-body-content" id="article-body-content"><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>TL;DR:</strong> If you’ve ever squinted at someone from across the bar and thought, “Wait, did I go to college with them?” Meta wants to help—and will likely open a can of worms in the process. The company is reportedly working on facial recognition for its Meta Ray-Ban smart glasses, reviving a technology it previously shut down over privacy concerns. This time, Meta is betting that both the product and the moment are finally in its favor.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>What happened: </strong><a href="https://www.nytimes.com/2026/02/13/technology/meta-facial-recognition-smart-glasses.html?unlocked_article_code=1.NVA.RUxv.gsaisbhvaxHe&amp;smid=url-share" target="_blank">The New York Times</a> first reported that Meta is working on facial recognition software, internally dubbed “Name Tag,” that would allow Ray-Ban wearers to identify people nearby and see information tied to their Meta profiles. The company says it will take a “thoughtful approach” to evaluating the feature and hasn’t announced an official launch, but reports say it could arrive as soon as this year. That would mark a notable reversal for a business that once argued the technology had become too risky to continue.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Context, please: </strong>This isn’t Meta’s first rodeo. It actually shut down <a href="https://www.theverge.com/2021/11/2/22759613/meta-facebook-face-recognition-automatic-tagging-feature-shutdown" target="_blank">Facebook’s original facial recognition system in 2021</a>, citing “growing societal concerns.” Along the way, Meta faced years of legal scrutiny, including a $5 billion Federal Trade Commission fine over privacy violations. The company also agreed to biometric data settlements totaling more than $2 billion in Illinois and Texas.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>What’s changed: </strong>A few things. First, Meta’s Ray-Ban glasses have quietly become one of the company’s rare hardware hits, selling millions of units (Zuck’s courthouse entourage <a href="https://www.businessinsider.com/mark-zuckerberg-courthouse-entourage-meta-ray-bans-addiction-trial-2026-2" target="_blank">even showed up wearing them</a> at trial yesterday). Facial recognition technology would make Meta’s glasses far more powerful—allowing its AI assistant to recognize people in real time and provide context automatically. Also worth noting: The political and regulatory environment has shifted under the Trump administration, which has signaled it <a href="https://www.theinformation.com/articles/meta-renews-work-facial-recognition-tech-privacy-worries-fade?ref=platformer.news" target="_blank">could be less aggressive</a> on privacy enforcement.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>What’s next:</strong> Glasses that recognize people raise painfully obvious questions, including whether people can be identified without consent or whether that data could eventually be accessed by law enforcement. (Reminder: Customs and Border Patrol agents <a href="https://www.404media.co/a-cbp-agent-wore-meta-smart-glasses-to-an-immigration-raid-in-los-angeles/" target="_blank">wore Meta glasses</a> to raids last year). And even in a friendlier regulatory environment, consumer backlash is still a risk. <a href="https://www.theringer.com/2026/02/18/tech/ring-super-bowl-ad-surveillance-state-meta-facial-recognition" target="_blank">Just look at the reaction</a> to the Amazon Ring Super Bowl ad, which led to an outcry about AI-powered surveillance. Meta has spent years betting on how much privacy people are willing to trade for convenience. Now, with AI glasses gaining traction and the environment shifting in its favor, it’s betting the answer might be: more than before. —<em>AC</em></p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Related story: </strong>Meta’s also got plans to <a href="https://www.theverge.com/tech/881065/meta-smartwatch-plans-2026?utm_campaign=etb&amp;utm_medium=newsletter&amp;utm_source=morning_brew" target="_blank">launch a smartwatch</a> later this year.</p></div>]]></content:encoded>
  <media:content url="https://morningbrew.com/cdn-cgi/image/width=1200,height=630,quality=70,format=auto/https://storage.morningbrew.com/image/2026-02-19/image-4c1be6ff1419e9962b5cc105fd77d7f2a54d2327-2000x1334-jpg/TB-Download-MetaGlasses-0226.jpg" medium="image"/>
</item>
<item>
  <title>Why it’s so hard to deploy AVs at airports</title>
  <link>https://www.techbrew.com/stories/2026/01/21/deploy-avs-at-airports</link>
  <pubDate>2026-01-21</pubDate>
  <dc:creator>Jordyn Grzelewski</dc:creator>
  <category>Emerging Tech</category>
  <description>Unlike your parents, your BFF, and your coworkers, robotaxi companies actually want to take you to the airport. But it’s easier said than done.</description>
  <content:encoded><![CDATA[<div class="style__ArticleBodyWrapper-sc-9b30af34-3 iUHyfu article-body-content" id="article-body-content"><p class="dist__StyledText-sc-5791265-8 bdIWsa">Bellowing law enforcement officers; impatient, inattentive, and incompetent drivers; inexplicable lane closures; travel-weary pedestrians, laden with literal and figurative baggage, wandering into traffic: These are just a few of the mainstays of the airport pickup and drop-off experience.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Robotaxi companies are eager to help you avoid asking your loved ones to experience this on your behalf. But first, they need to learn how to get to the airport.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“The appeal, of course, is that there’s a huge amount of rides,” Edwin Olson, CEO and founder of AV tech company <a href="https://www.techbrew.com/stories/2025/05/12/ride-along-driverless-may-mobility" target="_blank">May Mobility</a>, which has partnerships with <a href="https://www.techbrew.com/stories/2024/11/06/may-mobility-lyft-partnership-av" target="_blank">Lyft</a> and Uber, told us.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“There’s a lot of miles, and the challenge is that you’ve got a couple of things working against you from a technology perspective,” he said. “You end up with a lot of chaos, like travelers bumbling around the pickup-drop-off location.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Revenue opportunity: </strong>The reason AV companies want to get into the airport ride business is obvious: It’s a massive market. Even as far back as 2018, nearly four in 10 air travelers reported using ride-sharing, according to an HNTB survey. Lyft noted in 2025 that 61% of its riders have used the platform to book airport trips. And, Olson explained, it would be an efficient way to improve the financial proposition of autonomous ride-hailing by boosting utilization rates.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“If a significant fraction of rides are airport rides, then that creates a natural pressure that if you want to be able to put more vehicles into a market, you’re going to have to start taking those airport rides at some point. So it’s really a matter of, how do you grow your SAM to be a larger portion of the TAM?” he said, <a href="https://www.salesforce.com/blog/tam-sam-som/" target="_blank">referencing</a> serviceable addressable market and total addressable market.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“You can grow without airport trips, but eventually you’re going to need to be able to handle airport trips.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Airport trips also tend to be longer, Paul Miller, principal analyst at Forrester, noted, and therefore bring in higher rates (<em>looking at you, $100 trip to LaGuardia</em>).</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“You will have someone in the cab to the airport, and also someone there in the cab from the airport,” he added. “So it’s a good way to make money if you’re running a fleet of taxis.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Taking off: </strong>In the US, Alphabet-owned Waymo kicked off service to and from Phoenix Sky Harbor International Airport in Arizona a few years ago. Since then, it’s been a slow progression.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">In September, Waymo <a href="https://www.techbrew.com/stories/2025/09/17/waymo-airport-rides-san-francisco-san-jose" target="_blank">announced</a> it would be expanding its ride-hailing service to two California airports: San Francisco International and San Jose Mineta International.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“From freeways to airports, we look forward to continuing to help riders get where they need to go,” the company said in a December <a href="https://waymo.com/blog/2025/12/2025-year-in-review#:~:text=From%20freeways%20to%20airports%2C%20we,Here%27s%20to%20the%20road%20ahead" target="_blank">blog post</a>. “Airports are a top destination, as we’ve seen with our years of successful operations at Phoenix Sky Harbor International.” Waymo recently started offering autonomous rides to employees (its typical practice before rolling out service to the general public) at Miami International Airport, “with plans to go fully autonomous at other major airports soon.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Tesla leaders, too, want to launch airport robotaxi services in San Francisco, San Jose, and Oakland, California, Politico <a href="https://www.politico.com/news/2025/09/09/tesla-rides-san-francisco-san-jose-airports-00551469" target="_blank">reported</a> in September, and have initiated discussions with airport officials to start the necessary approval processes.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Roadblocks: </strong>However, there are considerable challenges standing in the way of widespread robotaxi use at airports.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">The most significant barrier, in Olson’s view, is that airport rides require robotaxis to have the ability to travel at highway speeds, which is a work in progress for the AV sector.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“Freeway segments require the vehicle to be able to see much farther, which typically comes with a higher bill of materials price for the vehicle, and also just amplifies all of the risk,” Olson said. “The faster you go, the more likely it is that if something does go wrong, that you’re going to have a really bad day…These are all very solvable problems, and I think we’re all eager to get into the airport business.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><em>Getting</em> to the airport is just the first of many challenges. Navigating airport campuses is even trickier.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“The roads are narrow and twisting, and there are things coming from left and from right,” Miller said. “There are people stopping at all sorts of bizarre times. I’m trying to get someone on a flight. I’m stopping here. I don’t care about the double yellow lines. I don’t care about that police officer walking toward me.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">That’s not all. Telecommunications traffic could jam vehicles’ GPS systems or interfere with various sensors, Miller said. Airports have heightened security requirements. “Security services tend to overreact to things in airports for very understandable reasons,” he added. “So you’re just adding complexity with the robotaxi.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">And, he noted, many airport parking lots and garages require a driver to take a ticket and then use the ticket to pay on their way out. “How does a robotaxi do that? You would have to change the physical infrastructure to have tags and sensors and things like that to allow the taxi to operate in that space.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">To make it feasible for robotaxis to operate at airports on a wide scale, Miller said that significant work will likely be needed, including building out infrastructure that can communicate with vehicles, updating lane markings, creating new ways to enforce traffic laws, and establishing dedicated robotaxi pickup and dropoff points. Finally, he noted, there are permitting requirements that companies have to go through in order to operate at airports.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Despite these barriers, Miller expects driverless taxi services to make it happen: “They all want to get it done, but they’re not going to rush it.”</p></div>]]></content:encoded>
  <media:content url="https://cdn.sanity.io/images/bl383u0v/production/b486c8f5e1c58bb84e17f0f54c5d9d5d2b3227a8-3000x2000.jpg?rect=0,212,3000,1575&amp;w=1200&amp;h=630&amp;q=70&amp;fit=crop&amp;auto=format" medium="image"/>
</item>
<item>
  <title>The ‘greener’ the data center, the greater the potential savings</title>
  <link>https://www.techbrew.com/stories/2026/01/13/green-data-centers-explained</link>
  <pubDate>2026-01-13</pubDate>
  <dc:creator>Tricia Crimmins</dc:creator>
  <category>Emerging Tech</category>
  <description>Data centers that prioritize clean energy and efficiency can save money and foster growth.</description>
  <content:encoded><![CDATA[<div class="style__ArticleBodyWrapper-sc-9b30af34-3 iUHyfu article-body-content" id="article-body-content"><p class="dist__StyledText-sc-5791265-8 bdIWsa">It’s no secret that the data centers powering the AI age are enormously expensive: Annual operating costs for each are estimated to be in the tens of millions, and just getting one off the ground costs billions.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">But once a data center is built, maintenance costs can be significantly reduced by fueling a majority of operations via clean energy, employing energy and water efficiency technologies, and computing sustainably. And while there’s no one-size-fits-all definition of a “green data center,” those that have been able to cut emissions and costs tend to focus on these fundamental practices.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Using idle energy: </strong>There are lots of data centers that run in part on clean energy from solar farms and rooftop and community solar, all of which can lower power prices. But to supercharge those savings, data-center developers can couple unused renewable energy with the need for more computing power.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Even though the US is facing an <a href="https://www.techbrew.com/stories/2025/07/24/wind-solar-energy-demand-senate-hearing" target="_blank">energy demand</a> crisis, a lot of renewable energy actually gets <a href="https://www.techbrew.com/stories/2025/07/10/how-vpps-help-renewable-energy-power-the-grid" target="_blank">wasted</a>. States like California and Texas get a higher percentage of energy from renewables like solar and wind—but because those sources of power flow mostly during the day when energy demand is lower, large swaths of clean energy don’t get used if it’s not stored in batteries. In an effort to absorb some of that energy that would otherwise go to waste, Soluna Holdings, a data center developer, locates solar and wind farms that produce more than can be consumed and builds data centers nearby.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“There’s a lot of power in the grid,” CEO John Belizaire told Morning Brew. “You’ve just got to look in the right place.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Once Soluna finds applicable renewable farms, it enhances the substation that connects the facility to the grid to allow it to power a data center, too. And when the data center is up and running, it's powered mostly by clean energy (though it can draw energy from the grid when needed).</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Because clean energy <a href="https://www.techbrew.com/stories/2025/08/04/solar-power-will-survive-tax-credit-cuts-but-consumers-will-pay" target="_blank">tax credits</a> function on a “use it or lose it” basis, Belizaire said that Soluna eating up wasted energy benefits the renewable investors it partners with, too. The company currently has 2.8 gigawatts of data center projects in Texas.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“Where these [solar and wind farms] are located, there’s not a lot of load, and so it’s very hard for them to offload that power. They end up having to turn off the facilities, or half of the facility, and that can have a materially negative effect on their revenues and profit as an enterprise, and so we provide them a solution to that,” Belizaire said. “Computing should move closer to energy.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Holistic efficiency: </strong>It’s not just the <em>type</em> of energy data centers use, but also <em>how</em> it’s used. Aaron Binkley, the VP of sustainability at data center developer Digital Realty, told us that energy efficiency starts with how buildings are constructed. Digital Realty’s buildings are LEED certified by the US Green Building Council “across 100+ different environmental metrics.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“That’s the materials, that’s the construction process, it’s the water and energy performance of the data centers’ design,” Binkley said. “And then when we do need to do retrofits or refurbishments of those facilities, we’'re looking at sustainable aspects of the refurbishment over the life cycle of the building.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Digital Realty’s green building design results in a 10%–25% improvement in energy efficiency and a 75%–90% reduction in water usage compared with a typical data center, which uses evaporative water cooling. Digital Realty uses air cooling at a majority of its data centers, and funnels recycled and reclaimed water for sinks, toilets, and landscaping.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“We’re typically using about the same amount or less water than the same size office building,” Binkley said.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">All in all, Binkley said Digital Realty takes a well-rounded approach to sustainability.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“There may be some industry participants that are very good on the new construction, maybe less focused operationally. Others that are maybe very dialed in on operations, but don’t do much on the construction side,” he said. “Where I feel we’ve built a good mousetrap is to look at it holistically.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Computing responsibly: </strong>A huge part of energy efficiency and sustainability is making sure that the computing equipment data centers are running on is efficient, too. Hillery Hunter, the GM of IBM Power and CTO of IBM Infrastructure, told us that the hardware and software used inside data centers are just as important as the type of energy being used to power the entire operation. “Because otherwise you’re just talking about, how renewable is the energy you’re wasting?”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">She said when IBM operates data centers for its clients, the company recommends using up-to-date computer servers and optimizing the computers, data storage, and network for efficiency. On top of that, IBM monitors hardware efficiency so clients aren’t “just buying more and more servers, [they’re] getting the maximum out of them.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Those optimizations can pay dividends: Hunter said that data centers using the most efficient hardware and software available can see up to an 80% reduction in their carbon footprint. And sustainability gains are more than just environmentally conscious and cost-saving—they’re also necessary for future advancement.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“If you’re not addressing sustainability, you’re not going to be able to fit the computing for AI, for example, into your data center,” Hunter said. “Sustainability isn’t a standalone topic. It’s not just a standalone goal. It’s really the foundation for growth.”</p></div>]]></content:encoded>
  <media:content url="https://cdn.sanity.io/images/bl383u0v/production/0830f5a75ae710c7e26c197600c69d1eb5c94cea-3000x2000.jpg?rect=0,212,3000,1575&amp;w=1200&amp;h=630&amp;q=70&amp;fit=crop&amp;auto=format" medium="image"/>
</item>
<item>
  <title>Why is everyone in AI talking about world models?</title>
  <link>https://www.techbrew.com/stories/2025/12/18/world-models-ai</link>
  <pubDate>2025-12-18</pubDate>
  <dc:creator>Patrick Kulp</dc:creator>
  <category>Emerging Tech</category>
  <description>Some AI luminaries are positioning them as the next big phase for AI progress.</description>
  <content:encoded><![CDATA[<div class="style__ArticleBodyWrapper-sc-9b30af34-3 iUHyfu article-body-content" id="article-body-content"><p class="dist__StyledText-sc-5791265-8 bdIWsa">For years, the startup Runway has built its reputation as a <a href="https://www.techbrew.com/stories/2025/06/06/runway-ai-film-festival-2025" target="_blank">purveyor of AI in Hollywood</a>, signing on studios and filmmakers to use its video models. But the company recently opened up a new line of business aimed at a wider clientele, including robotics companies and video game makers.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Runway’s new family of world models is designed to combine the photorealistic imagery it offers moviemakers with physics prompts that will generate fully simulated real-world environments.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“Our perspective is that world models are really the most important problem that we need to solve in order to further advance the field,” Runway CTO and co-founder Anastasis Germanidis told us. “The next stage will be about building systems that can interact with the physical world and understand the physical world. And text alone cannot get us there.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">After two years in the works, the project is arriving at a buzzy time for the concept of world models. Some AI luminaries argue that the scaling laws that have allowed AI labs to squeeze better performance from ever-bigger models won’t hold much longer. World models—billed in some cases as a way to better orient foundation models in real-life physical environments—have been floated as a next phase for AI progress.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Early machine learning pioneer Yann LeCun is <a href="https://www.bbc.com/news/articles/cdx4x47w8p1o" target="_blank">reportedly preparing</a> to leave his longtime post as Meta’s chief scientist to found a startup focused on world models. World Labs, founded by computer vision pioneer Fei-Fei Li, recently launched its <a href="https://techcrunch.com/2025/11/12/fei-fei-lis-world-labs-speeds-up-the-world-model-race-with-marble-its-first-commercial-product/" target="_blank">first commercial world model</a>, Marble. <a href="https://deepmind.google/blog/genie-3-a-new-frontier-for-world-models/" target="_blank">Google</a>, <a href="https://www.nvidia.com/en-us/ai/cosmos/" target="_blank">Nvidia</a>, and <a href="https://ai.meta.com/blog/v-jepa-2-world-model-benchmarks/" target="_blank">Meta</a> have built their own, too.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“I’ve been not making friends in various corners of Silicon Valley, including at Meta, saying that within three to five years, this [world models, not LLMs] will be the dominant model for AI architectures, and nobody in their right mind would use LLMs of the type that we have today,” LeCun said at a recent MIT symposium, according to <a href="https://www.wsj.com/tech/ai/yann-lecun-ai-meta-0058b13c" target="_blank">The Wall Street Journal</a>.</p><h3 class="dist__StyledText-sc-5791265-8 fPysEE"><strong>What in the world?</strong></h3><p class="dist__StyledText-sc-5791265-8 bdIWsa">But what exactly <em>is</em> a world model? Like <a href="https://www.techbrew.com/stories/2025/02/07/what-is-an-ai-agent" target="_blank">“agents” before it</a>, the term is definitionally vague, not actually new, and in danger of becoming freighted with hype, experts told us. At their most generalized, world models are a representation of the physical world that capture the relationships between objects and can predict how they will behave over time.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“A lot of people look at world models as something that can understand how the world changes. And you can interpret that sentence in many different ways,” Ranjay Krishna, an assistant professor at the University of Washington and researcher at the Allen Institute for AI. “One simple version of this interpretation is to say that if I was to take an action, like push something, what would happen? Maybe something might fall down, maybe it might collide with something else. Being able to predict how things would change, how the future states of the world are going to look…that’s one interpretation.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Krishna said other interpretations might include a more viewpoint-oriented conception of a fixed world or an understanding of social actors within a world.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">World models can also refer to a system of understanding within foundation models that might help them fill in cognitive gaps, Eric Landau, CEO and co-founder of AI data platform Encord, told us. Encord offers what it claims is the world’s largest open-source multimodal dataset, which can help train world models.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“[LLMs] take in statistical patterns, and they output other statistical patterns without having a deeper understanding of what is driving those statistical patterns,” Landau said. “It’s fundamentally missing some of the components that make human thinking the core of what it is. We can reason from first principles. We have a deeper understanding of what happens around us.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">For Runway, Germanidis said building a world model was a natural continuation of work the company was already doing on its video models (which are sort of “a poor man’s world model,” in Krishna’s words). Runway’s new family of world models includes first-person navigation through a generated world, a simulation specific to robotics, and one involving conversational avatar characters.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“Data collection in robotics is super slow,” Germanidis said. “[The new use case is] essentially providing a simulated environment where you can run your robotics model.”</p><h3 class="dist__StyledText-sc-5791265-8 fPysEE"><strong>Roadblocks ahead</strong></h3><p class="dist__StyledText-sc-5791265-8 bdIWsa">While the concept of world models is not new, the term may be gaining traction now because of advances in image and video generation models, which can serve as a base for a world model, Krishna said. But major challenges lie ahead in scaling up world models, he added. One is the amount of available data.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“A lot of [existing] video data is not directly usable,” Krishna said. “You need to figure out how the world is changing, how the camera is moving around in that world, and then be able to encode that into your model somehow. And that’s not very easy.”</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Another potential hurdle is the massive amount of compute needed for video models, which dwarfs even the demands of LLMs, according to Krishna. And plotting out a world is a much more structured process than stringing together a sentence, he said.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">“If this continues, we likely will get to a point where things are going to really start speeding up…With the amount of investment and the amount of people interested in this space, there is a good chance that we’ll figure out some of those big challenges,” Krishna said. “I think that’s why people are excited. It’s likely that we’re going to see more startups. But just like with any other technology, I’m sure that we will see that same sort of plateau. But the question is, ‘How long until we see that plateau?’”</p></div>]]></content:encoded>
  <media:content url="https://cdn.sanity.io/images/bl383u0v/production/0edfe9ff490de3639b8015aa746cdf3b8dc832f9-1500x1000.png?rect=0,106,1500,788&amp;w=1200&amp;h=630&amp;q=70&amp;fit=crop&amp;auto=format" medium="image"/>
</item>
<item>
  <title>What we’re looking for at CES</title>
  <link>https://www.techbrew.com/stories/2025/12/18/what-were-looking-for-at-ces-2026</link>
  <pubDate>2025-12-18</pubDate>
  <dc:creator>Tricia Crimmins,</dc:creator>
  <category>Emerging Tech</category>
  <description>Morning Brew’s new Enterprise Tech team is headed to Vegas.</description>
  <content:encoded><![CDATA[<div class="style__ArticleBodyWrapper-sc-9b30af34-3 iUHyfu article-body-content" id="article-body-content"><p class="dist__StyledText-sc-5791265-8 bdIWsa">Morning Brew is debuting an Enterprise Tech team to deeply cover the intersection of business and technology across the Extended Brewniverse.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">To kick off this new endeavor, our whole crew is headed to Las Vegas for CES 2026. Unlike in years past, we haven’t scheduled back-to-back meetings and jammed our calendars full of demos. We’ve penciled in a few test runs and plan to attend a few panels, sure, but we’re mostly just going to walk around and see what intrigues us to gather string for our reporting in the New Year.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Here’s what we’ll have our eyes on.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Tricia Crimmins, Enterprise Reporter, Tech: </strong>For my first go at CES, I’m excited to learn more about recycling tech. I recently spoke with Ivan Arbouzov, the CEO of Clear Drop, a company that makes a soft plastic compactor. The machine compresses and slightly melts soft plastic—like grocery bags, plastic wrap, etc.—into a solid brick, which users then ship to Clear Drop recycling partners via USPS.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">Arbouzov told me that in addition to selling the product, he feels that Clear Drop gives customers a way to assuage some of the guilt they might feel about so much plastic getting produced and wasted. I’m looking forward to finding more products that help individual consumers contribute to processes with public benefit.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Jordyn Grzelewski, Senior Enterprise Reporter, Tech:</strong> This will be my second consecutive year at CES. In 2025, I spent much of my time in the West Hall, home to lots of the auto and mobility tech on display at the show, and <a href="https://www.techbrew.com/stories/2025/01/16/software-defined-vehicles-ai-av-ces-2025" target="_blank">noted</a> the focus on trends like software-defined vehicles, how GenAI was being integrated into vehicles, and advancements in AV tech.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">This time around, I’ll be curious to see how the renewed hype around robotaxis is reflected at CES, especially given the <a href="https://www.techbrew.com/stories/2025/11/26/waymo-expands-robotaxi-rides-av-sector-news" target="_blank">acceleration in deployments</a> in 2025. I’ll be keeping an eye out for cool mobility tech beyond the automotive realm (I have some interesting pitches in my inbox related to <a href="https://www.techbrew.com/stories/2025/12/02/electric-rv-startup-lightship-2026-plans" target="_blank">electric RVs</a> and <a href="https://www.techbrew.com/stories/2025/05/28/electric-boat-maker-arc-commercial-marine-segment" target="_blank">boats</a>). And with the GenAI hype cycle reaching a fever pitch between CES 2025 and CES 2026, I’ll be interested to see just how real and compelling some of the in-vehicle integrations of <a href="https://www.techbrew.com/stories/2025/11/10/ai-vehicles-gm-rivian" target="_blank">AI chatbots</a> and other AI-powered features appear to be.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Patrick Kulp, Senior Enterprise Reporter, Tech:</strong> Having mostly covered AI in the 1s and 0s realm, I’m interested to see how companies are trying to give the tech a physical interface at a show best known for gadgets. Last time I was there, in 2024, a little red AI assistant device called the Rabbit R1 was <a href="https://www.tomsguide.com/features/rabbits-r1-ai-device-took-ces-2024-by-storm-what-is-it-and-why-might-you-want-one" target="_blank">all the rage</a>. Lots of <a href="https://www.wired.com/review/rabbit-r1/" target="_blank">bad</a> <a href="https://www.theverge.com/2024/5/2/24147159/rabbit-r1-review-ai-gadget" target="_blank">reviews</a> later, <a href="https://www.tomsguide.com/ai/whats-next-for-rabbit-employees-say-they-havent-been-paid-for-months-while-company-teases-new-ai-hardware" target="_blank">a report</a> last month said the startup has had trouble paying employees. Other flash-in-the-pan AI-native devices have <a href="https://www.sfgate.com/tech/article/humane-ai-shuts-down-flop-20175974.php" target="_blank">similarly faded</a>.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">But there’s a whole world now of AI PCs, wearables, and robotics that are attempting to make AI physical in various ways. I’m curious to see how many of these AI elements are actually worthwhile. Last time I was at CES, a lot of generative AI-infused devices felt gimmicky or unpolished. But two years is an eternity in the fast-moving AI world.</p><p class="dist__StyledText-sc-5791265-8 bdIWsa"><strong>Annie Saunders, Enterprise Editor, Tech:</strong> I’ll have my eyes peeled for tech that aims to increase accessibility. While often geared toward individuals with disabilities or other limitations, accessibility tech ultimately benefits everyone at some point. (Ever turn on subtitles when watching a show with whispered dialogue, or zoom in on text? That’s accessibility tech!)</p><p class="dist__StyledText-sc-5791265-8 bdIWsa">I’m already planning to test out a few bionic footwear devices, including one called Sidekick from Dephy. But I’ll be on the lookout for similar tech as I stroll across the Vegas convention floors—with or without bionic assistance.</p></div>]]></content:encoded>
  <media:content url="https://cdn.sanity.io/images/bl383u0v/production/d1d254142c71d48d7453502d2569ae9316a51403-4000x2667.jpg?rect=0,283,4000,2100&amp;w=1200&amp;h=630&amp;q=70&amp;fit=crop&amp;auto=format" medium="image"/>
</item>
</channel>
</rss>